{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import cv2\n",
    "\n",
    "from torchvision.transforms.functional import resize, to_pil_image, to_tensor\n",
    "from torchvision.transforms import Compose, ToPILImage, Resize, ToTensor\n",
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, Rotate, Normalize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image and mask directories\n",
    "image_directory = 'processed_data/npy_tiles/rgbs'\n",
    "mask_directory = 'processed_data/npy_tiles/masks'\n",
    "\n",
    "# List all image and mask files\n",
    "image_files = sorted([f for f in os.listdir(image_directory) if f.lower().endswith('.npy')])\n",
    "mask_files = sorted([f for f in os.listdir(mask_directory) if f.lower().endswith('.npy')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display a sample image and mask\n",
    "sample_image = np.load(os.path.join(image_directory, image_files[6733]))\n",
    "sample_mask = np.load(os.path.join(mask_directory, mask_files[6733]))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(sample_image / 255.0)\n",
    "ax[0].set_title(\"Sample Image\")\n",
    "ax[1].imshow(sample_mask.squeeze(), cmap='gray')\n",
    "ax[1].set_title(\"Sample Mask\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set image and mask directories\n",
    "image_directory = 'processed_data/npy_tiles/rgbs'\n",
    "mask_directory = 'processed_data/npy_tiles/masks'\n",
    "\n",
    "# List all image and mask files\n",
    "image_files = sorted([f for f in os.listdir(image_directory) if f.lower().endswith('.npy')])\n",
    "mask_files = sorted([f for f in os.listdir(mask_directory) if f.lower().endswith('.npy')])\n",
    "\n",
    "# Load a sample image and mask\n",
    "sample_image = np.load(os.path.join(image_directory, image_files[0]))\n",
    "sample_mask = np.load(os.path.join(mask_directory, mask_files[0]))\n",
    "\n",
    "# Print out the properties of the image and mask\n",
    "print(f\"Sample Image:\")\n",
    "print(f\"Shape: {sample_image.shape}\")\n",
    "print(f\"Data type: {sample_image.dtype}\")\n",
    "print(f\"Min value: {sample_image.min()}\")\n",
    "print(f\"Max value: {sample_image.max()}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Sample Mask:\")\n",
    "print(f\"Shape: {sample_mask.shape}\")\n",
    "print(f\"Data type: {sample_mask.dtype}\")\n",
    "print(f\"Unique values: {np.unique(sample_mask)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_statistics(image_directory, num_channels=3):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of the dataset.\n",
    "    Args:\n",
    "        image_directory (str): Path to the directory with images.\n",
    "        num_channels (int): Number of image channels.\n",
    "\n",
    "    Returns:\n",
    "        mean (list): Mean value for each channel.\n",
    "        std (list): Standard deviation for each channel.\n",
    "    \"\"\"\n",
    "    total_sum = np.zeros(num_channels)\n",
    "    total_sq_sum = np.zeros(num_channels)\n",
    "    total_num_pixels = 0\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(image_directory) if f.lower().endswith('.npy')])\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image = np.load(os.path.join(image_directory, image_file))\n",
    "        total_sum += image.sum(axis=(0, 1))\n",
    "        total_sq_sum += np.sum(np.square(image), axis=(0, 1))\n",
    "        total_num_pixels += np.prod(image.shape[:2])\n",
    "\n",
    "    mean = total_sum / total_num_pixels\n",
    "    std = np.sqrt((total_sq_sum / total_num_pixels) - np.square(mean))\n",
    "\n",
    "    return mean.tolist(), std.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dataset statistics\n",
    "mean, std = calculate_dataset_statistics(image_directory)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard deviation: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation pipelines\n",
    "transforms = Compose([\n",
    "    Normalize(mean=mean, std=std, always_apply=True, p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class ConstructionDataset(Dataset):\n",
    "    def __init__(self, image_directory, mask_directory, transforms=None):\n",
    "        self.image_files = sorted([f for f in os.listdir(image_directory) if f.lower().endswith('.npy')])\n",
    "        self.mask_files = sorted([f for f in os.listdir(mask_directory) if f.lower().endswith('.npy')])\n",
    "        self.image_directory = image_directory\n",
    "        self.mask_directory = mask_directory\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Load image and mask\n",
    "        img_name = os.path.join(self.image_directory, self.image_files[idx])\n",
    "        mask_name = os.path.join(self.mask_directory, self.mask_files[idx])\n",
    "        image = np.load(img_name)\n",
    "        mask = np.load(mask_name)\n",
    "\n",
    "        # Modify the mask to have a single channel and convert to float\n",
    "        mask = mask.reshape((1, mask.shape[0], mask.shape[1])).astype(np.float32)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # Remove the channel dimension from the mask if it exists\n",
    "        #if mask.ndim > 2:\n",
    "            #mask = mask.squeeze(-1)\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask': mask\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a dataset instance\n",
    "dataset = ConstructionDataset(image_directory, mask_directory, transforms=transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of training data\n",
    "data = next(iter(train_loader))\n",
    "\n",
    "# Extract image and mask from the batch\n",
    "image_ds_viz = data['image'][0].cpu().numpy()  # Get the first image of the batch\n",
    "mask = data['mask'][0].cpu().numpy()  # Get the corresponding mask\n",
    "\n",
    "# For visualization purposes, we might need to transpose the image back to HxWxC format from CxHxW\n",
    "image_ds_viz = np.transpose(image_ds_viz, (1, 2, 0))\n",
    "image_ds_viz = (image_ds_viz * std) + mean  # denormalize\n",
    "image_ds_viz = image_ds_viz * 255.0\n",
    "image_ds_viz = image_ds_viz.astype(np.uint8)  # convert to integers\n",
    "\n",
    "if mask.ndim == 3:  # Only transpose if mask has 3 dimensions\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "\n",
    "# Visualize the image and mask\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(image_ds_viz)\n",
    "ax[0].set_title('Image')\n",
    "\n",
    "ax[1].imshow(mask.squeeze(), cmap='gray')  # Use squeeze() to remove single-dimensional entries from the shape of the mask.\n",
    "ax[1].set_title('Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture for image segmentation.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            \"\"\"Create a convolutional block with two convolutional layers and ReLU activations.\"\"\"\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        def upsample(in_channels, out_channels):\n",
    "            \"\"\"Create an upsampling layer using transposed convolution.\"\"\"\n",
    "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "        # Define encoder blocks\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        self.encoder5 = conv_block(512, 1024)\n",
    "        self.encoder6 = conv_block(1024, 2048)\n",
    "\n",
    "        # Define middle block\n",
    "        self.middle = conv_block(2048, 4096)\n",
    "\n",
    "        # Define decoder blocks\n",
    "        self.decoder6 = conv_block(4096, 2048)\n",
    "        self.decoder5 = conv_block(2048, 1024)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "        self.decoder0 = conv_block(64, 32)\n",
    "\n",
    "        # Define upsampling layers\n",
    "        self.upsample6 = upsample(4096, 2048)\n",
    "        self.upsample5 = upsample(2048, 1024)\n",
    "        self.upsample4 = upsample(1024, 512)\n",
    "        self.upsample3 = upsample(512, 256)\n",
    "        self.upsample2 = upsample(256, 128)\n",
    "        self.upsample1 = upsample(128, 64)\n",
    "\n",
    "        # Define pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Define output convolution\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode input through encoder blocks\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "        enc5 = self.encoder5(self.pool(enc4))\n",
    "        enc6 = self.encoder6(self.pool(enc5))\n",
    "\n",
    "        # Pass through middle block\n",
    "        middle = self.middle(self.pool(enc6))\n",
    "\n",
    "        # Decode and upsample\n",
    "        dec6 = self.upsample6(middle)\n",
    "        dec6 = torch.cat((dec6, enc6), dim=1)\n",
    "        dec6 = self.decoder6(dec6)\n",
    "\n",
    "        dec5 = self.upsample5(dec6)\n",
    "        dec5 = torch.cat((dec5, enc5), dim=1)\n",
    "        dec5 = self.decoder5(dec5)\n",
    "\n",
    "        dec4 = self.upsample4(dec5)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "\n",
    "        dec3 = self.upsample3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "\n",
    "        dec2 = self.upsample2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "\n",
    "        dec1 = self.upsample1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        dec0 = self.decoder0(dec1)\n",
    "\n",
    "        # Generate output mask\n",
    "        out = self.out_conv(dec0)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = UNet(3, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "# Train and validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for images, masks in train_loader:\n",
    "        images = data['image'].to(device)\n",
    "        masks = data['mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = data['image'].to(device)\n",
    "            masks = data['mask'].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample prediction\n",
    "sample_image, sample_mask = val_dataset[0]\n",
    "sample_image = sample_image.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(sample_image)\n",
    "\n",
    "output_mask = (output > 0).squeeze().cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(sample_image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "ax[0].set_title(\"Input Image\")\n",
    "ax[1].imshow(sample_mask.squeeze(), cmap=\"gray\")\n",
    "ax[1].set_title(\"Ground Truth Mask\")\n",
    "ax[2].imshow(output_mask, cmap=\"gray\")\n",
    "ax[2].set_title(\"Predicted Mask\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample prediction\n",
    "sample_image, sample_mask = val_dataset[0]\n",
    "sample_image = sample_image.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(sample_image)\n",
    "\n",
    "output_mask = (output > 0).squeeze().cpu().numpy()\n",
    "\n",
    "# Normalize the image for display\n",
    "image_display = sample_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "image_display = (image_display - image_display.min()) / (image_display.max() - image_display.min())\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(image_display)\n",
    "ax[0].set_title(\"Input Image\")\n",
    "ax[1].imshow(sample_mask.squeeze(), cmap=\"gray\")\n",
    "ax[1].set_title(\"Ground Truth Mask\")\n",
    "ax[2].imshow(output_mask, cmap=\"gray\")\n",
    "ax[2].set_title(\"Predicted Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def output_to_binary_mask(output, threshold=0.5):\n",
    "    prob = sigmoid(output)\n",
    "    mask = (prob > threshold).astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    union = np.logical_or(y_true, y_pred)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score\n",
    "\n",
    "model.eval()\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in val_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        y_true_list.extend(masks.cpu().numpy().flatten())\n",
    "        y_pred_list.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "y_true = np.array(y_true_list)\n",
    "y_pred_list = np.array(y_pred_list)  # Convert the list to a NumPy array\n",
    "y_pred_binary = output_to_binary_mask(y_pred_list)\n",
    "\n",
    "precision = precision_score(y_true, y_pred_binary)\n",
    "recall = recall_score(y_true, y_pred_binary)\n",
    "f1 = f1_score(y_true, y_pred_binary)\n",
    "iou_score = iou(y_true, y_pred_binary)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"IoU: {iou_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"unet_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for further use or evaluation\n",
    "loaded_model = UNet(3, 1)\n",
    "loaded_model.load_state_dict(torch.load(\"unet_model.pth\"))\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display predictions for a number of samples from the validation set\n",
    "num_samples = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, masks) in enumerate(val_loader):\n",
    "        if i == num_samples:\n",
    "            break\n",
    "\n",
    "        images = images.to(device)\n",
    "        masks = masks.cpu().numpy()\n",
    "\n",
    "        outputs = model(images)  # Ensure you're using the correct model here\n",
    "        predicted_masks = (outputs > 0).cpu().numpy()  # I've replaced output_to_binary_mask with a simple threshold operation\n",
    "\n",
    "        for idx in range(images.size(0)):\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "            # Normalize the image for display\n",
    "            image_display = images[idx].permute(1, 2, 0).cpu().numpy()\n",
    "            image_display = (image_display - image_display.min()) / (image_display.max() - image_display.min())\n",
    "\n",
    "            ax1.imshow(image_display)\n",
    "            ax1.set_title(\"Input Image\")\n",
    "            ax1.axis(\"off\")\n",
    "\n",
    "            ax2.imshow(masks[idx][0], cmap=\"gray\")\n",
    "            ax2.set_title(\"Ground Truth\")\n",
    "            ax2.axis(\"off\")\n",
    "\n",
    "            ax3.imshow(predicted_masks[idx][0], cmap=\"gray\")\n",
    "            ax3.set_title(\"Predicted Mask\")\n",
    "            ax3.axis(\"off\")\n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
